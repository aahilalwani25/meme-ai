{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pradeep2c1/Machine-Translation-model/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aByTLISdCSpp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvs3YYFrYXmN",
    "outputId": "936355b6-4805-4255-f2db-63446474b132"
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "kcz51fdAYp_8",
    "outputId": "08d6dc6e-ce6b-4b7f-8283-70d0864babe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4dOWFN2YO83"
   },
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8B5h0UHMmEgQ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'urdu_english.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REzTYEAEmYlu",
    "outputId": "656c2d6d-8995-4fdc-f500-5960b824bd05"
   },
   "outputs": [],
   "source": [
    "#df['source'].value_counts()\n",
    "df= df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "NU6z_ZbLs8N7",
    "outputId": "dd856585-db0d-4035-ece1-25fe770eafce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what's the name of the movie</td>\n",
       "      <td>film ka kya naam hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi, the rotten tomatoes score is great but the...</td>\n",
       "      <td>namaste, sada hua tomatoes score mahaan hai, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do you think you will like the movie</td>\n",
       "      <td>kya aapako lagata hai ki aapako film pasand aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what kind of movie is it</td>\n",
       "      <td>yah kis tarah kee philm hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when was the movie made?</td>\n",
       "      <td>film  kab banee thee?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wonder woman, i think i would enjoy this movie...</td>\n",
       "      <td>aashchary hai ki mahila, mujhe lagata hai ki m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>whats the name of the movie</td>\n",
       "      <td>film ka kya naam hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it is a action movie set in the dc comic world</td>\n",
       "      <td>yah deesee komik duniya mein sthaapit ek eksha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>who stars in the movie</td>\n",
       "      <td>: film mein kaun sitaare hain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the movie was made in 2015</td>\n",
       "      <td>movie 2015 mein banee thee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    english_sentence  \\\n",
       "0                       what's the name of the movie   \n",
       "1  hi, the rotten tomatoes score is great but the...   \n",
       "2               do you think you will like the movie   \n",
       "3                           what kind of movie is it   \n",
       "4                           when was the movie made?   \n",
       "5  wonder woman, i think i would enjoy this movie...   \n",
       "6                        whats the name of the movie   \n",
       "7     it is a action movie set in the dc comic world   \n",
       "8                             who stars in the movie   \n",
       "9                         the movie was made in 2015   \n",
       "\n",
       "                                       urdu_sentence  \n",
       "0                               film ka kya naam hai  \n",
       "1  namaste, sada hua tomatoes score mahaan hai, l...  \n",
       "2  kya aapako lagata hai ki aapako film pasand aa...  \n",
       "3                        yah kis tarah kee philm hai  \n",
       "4                              film  kab banee thee?  \n",
       "5  aashchary hai ki mahila, mujhe lagata hai ki m...  \n",
       "6                               film ka kya naam hai  \n",
       "7  yah deesee komik duniya mein sthaapit ek eksha...  \n",
       "8                      : film mein kaun sitaare hain  \n",
       "9                         movie 2015 mein banee thee  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df[df['source'] == 'ted']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWUF8i3eNBNG",
    "outputId": "f3baa0b6-982b-42f1-f235-5b3704c179b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.drop(columns = ['source'], inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8Y7POK6xYn3r"
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)\n",
    "#df.drop(columns = ['index'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmpewEf60IGd",
    "outputId": "2256d44f-a7fa-46e2-a4e5-eb0f422d47ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index               0\n",
       "english_sentence    0\n",
       "urdu_sentence       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbHkhHLk8_S0",
    "outputId": "f79a482f-a6fc-4ee0-f998-52298d1b2f55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jLLZJ7tdX_38",
    "outputId": "951f88a8-5fc6-4cd7-a85f-7a86ee87a007"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what's the name of the movie</td>\n",
       "      <td>film ka kya naam hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hi, the rotten tomatoes score is great but the...</td>\n",
       "      <td>namaste, sada hua tomatoes score mahaan hai, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>do you think you will like the movie</td>\n",
       "      <td>kya aapako lagata hai ki aapako film pasand aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what kind of movie is it</td>\n",
       "      <td>yah kis tarah kee philm hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>when was the movie made?</td>\n",
       "      <td>film  kab banee thee?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   english_sentence  \\\n",
       "0      0                       what's the name of the movie   \n",
       "1      1  hi, the rotten tomatoes score is great but the...   \n",
       "2      2               do you think you will like the movie   \n",
       "3      3                           what kind of movie is it   \n",
       "4      4                           when was the movie made?   \n",
       "\n",
       "                                       urdu_sentence  \n",
       "0                               film ka kya naam hai  \n",
       "1  namaste, sada hua tomatoes score mahaan hai, l...  \n",
       "2  kya aapako lagata hai ki aapako film pasand aa...  \n",
       "3                        yah kis tarah kee philm hai  \n",
       "4                              film  kab banee thee?  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vtTASV7GHewD"
   },
   "outputs": [],
   "source": [
    "# Make all english letters lowercase\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove the quotes\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df['urdu_sentence'] = df['urdu_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "# Remove special characters\n",
    "sp_char = set(string.punctuation)\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in sp_char))\n",
    "df['urdu_sentence'] = df['urdu_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in sp_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KfuxP2pXYO9E"
   },
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: x.strip())\n",
    "df['urdu_sentence']=df['urdu_sentence'].apply(lambda x: x.strip())\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "df['urdu_sentence']=df['urdu_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RJZsWTHZnlY1"
   },
   "outputs": [],
   "source": [
    "# Add START and END tokens to the beginning and end of the target sequence\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: 'START_ ' + x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "O1jcj84GLMVM",
    "outputId": "f6d2fbf8-24a8-42b1-93fc-ef443246bde8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>START_ whats the name of the movie _END</td>\n",
       "      <td>film ka kya naam hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>START_ hi the rotten tomatoes score is great b...</td>\n",
       "      <td>namaste sada hua tomatoes score mahaan hai lek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>START_ do you think you will like the movie _END</td>\n",
       "      <td>kya aapako lagata hai ki aapako film pasand aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>START_ what kind of movie is it _END</td>\n",
       "      <td>yah kis tarah kee philm hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>START_ when was the movie made _END</td>\n",
       "      <td>film kab banee thee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   english_sentence  \\\n",
       "0      0            START_ whats the name of the movie _END   \n",
       "1      1  START_ hi the rotten tomatoes score is great b...   \n",
       "2      2   START_ do you think you will like the movie _END   \n",
       "3      3               START_ what kind of movie is it _END   \n",
       "4      4                START_ when was the movie made _END   \n",
       "\n",
       "                                       urdu_sentence  \n",
       "0                               film ka kya naam hai  \n",
       "1  namaste sada hua tomatoes score mahaan hai lek...  \n",
       "2  kya aapako lagata hai ki aapako film pasand aa...  \n",
       "3                        yah kis tarah kee philm hai  \n",
       "4                                film kab banee thee  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6tOma5CQYl8X",
    "outputId": "db46aef2-51d0-4293-98ab-c36115d64a23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>309</td>\n",
       "      <td>START_ hi _END</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1404</td>\n",
       "      <td>START_ yes i know the term deutsches heer is a...</td>\n",
       "      <td>haan main jaanta hu ye term deutsches heer mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2896</td>\n",
       "      <td>START_ did you read the book the movie was bas...</td>\n",
       "      <td>kya aap us book ko read kiya jo yeh movie the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>748</td>\n",
       "      <td>START_ i didnt realize i had already seen it u...</td>\n",
       "      <td>i didnt realize i had already seen it until i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2902</td>\n",
       "      <td>START_ it is and what a crazy story basically ...</td>\n",
       "      <td>ye hai kya crazy story hai basically wo dumped...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   english_sentence  \\\n",
       "0    309                                     START_ hi _END   \n",
       "1   1404  START_ yes i know the term deutsches heer is a...   \n",
       "2   2896  START_ did you read the book the movie was bas...   \n",
       "3    748  START_ i didnt realize i had already seen it u...   \n",
       "4   2902  START_ it is and what a crazy story basically ...   \n",
       "\n",
       "                                       urdu_sentence  \n",
       "0                                                 hi  \n",
       "1  haan main jaanta hu ye term deutsches heer mod...  \n",
       "2  kya aap us book ko read kiya jo yeh movie the ...  \n",
       "3  i didnt realize i had already seen it until i ...  \n",
       "4  ye hai kya crazy story hai basically wo dumped...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1).reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQY65UsEYO-h"
   },
   "source": [
    "# Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "z6Gh2jx0YO-j"
   },
   "outputs": [],
   "source": [
    "en = set()\n",
    "for sentence in df['english_sentence']:\n",
    "    for word in sentence.split():\n",
    "        if word not in en:\n",
    "            en.add(word)\n",
    "\n",
    "hi = set()\n",
    "for sentence in df['urdu_sentence']:\n",
    "    for word in sentence.split():\n",
    "        if word not in hi:\n",
    "            hi.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KV8sLvrnYO-k",
    "outputId": "87a1833c-aeab-44b4-811a-50cc1143b035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in English are :  5216\n",
      "Unique words in urdu are :  7412\n"
     ]
    }
   ],
   "source": [
    "print('Unique words in English are : ', len(en))\n",
    "print('Unique words in urdu are : ', len(hi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NBF2-ex1YO-m",
    "outputId": "12e90d91-f677-43be-fa97-f10d93a859ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "      <th>length_en</th>\n",
       "      <th>length_ur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>309</td>\n",
       "      <td>START_ hi _END</td>\n",
       "      <td>hi</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1404</td>\n",
       "      <td>START_ yes i know the term deutsches heer is a...</td>\n",
       "      <td>haan main jaanta hu ye term deutsches heer mod...</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2896</td>\n",
       "      <td>START_ did you read the book the movie was bas...</td>\n",
       "      <td>kya aap us book ko read kiya jo yeh movie the ...</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>748</td>\n",
       "      <td>START_ i didnt realize i had already seen it u...</td>\n",
       "      <td>i didnt realize i had already seen it until i ...</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2902</td>\n",
       "      <td>START_ it is and what a crazy story basically ...</td>\n",
       "      <td>ye hai kya crazy story hai basically wo dumped...</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   english_sentence  \\\n",
       "0    309                                     START_ hi _END   \n",
       "1   1404  START_ yes i know the term deutsches heer is a...   \n",
       "2   2896  START_ did you read the book the movie was bas...   \n",
       "3    748  START_ i didnt realize i had already seen it u...   \n",
       "4   2902  START_ it is and what a crazy story basically ...   \n",
       "\n",
       "                                       urdu_sentence  length_en  length_ur  \n",
       "0                                                 hi          3          1  \n",
       "1  haan main jaanta hu ye term deutsches heer mod...         23         21  \n",
       "2  kya aap us book ko read kiya jo yeh movie the ...         15         13  \n",
       "3  i didnt realize i had already seen it until i ...         33         31  \n",
       "4  ye hai kya crazy story hai basically wo dumped...         24         18  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length_en'] = df['english_sentence'].apply(lambda x: len(x.split()))\n",
    "df['length_ur'] = df['urdu_sentence'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBdYEMDCYO-o",
    "outputId": "70c3250d-83f5-47d3-980a-9a39ee01443e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(747, 5)\n",
      "(657, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df[df['length_en'] > 20].shape)\n",
    "print(df[df['length_ur'] > 20].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EleKwN6ZYO-p",
    "outputId": "ecc9b403-03b1-472a-df96-08f33c3609dd"
   },
   "outputs": [],
   "source": [
    "# df = df[df['length_en'] <= 20]\n",
    "# df = df[df['length_ur'] <= 20]\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTgOsAssYO-q",
    "outputId": "51c3acdb-1f9d-4f15-8b05-a91b82c353a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length of inputs = 249\n",
      "Maximum sequence length of outputs = 273\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum sequence length of inputs =\", max(df['length_en']))\n",
    "print(\"Maximum sequence length of outputs =\", max(df['length_ur']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6U7JUwqYO-r",
    "outputId": "1c0a906a-8f52-402a-ca5f-b3221cae7f8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7412, 5216)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_encoder_seq_length = max(df['length_en'])\n",
    "max_decoder_seq_length = max(df['length_ur'])\n",
    "\n",
    "input_words = sorted(list(hi))\n",
    "target_words = sorted(list(en))\n",
    "num_encoder_tokens = len(hi)\n",
    "num_decoder_tokens = len(en)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5iP6_8xWYO-s"
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens += 1\n",
    "num_decoder_tokens += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HwHCkRaCYO-s"
   },
   "outputs": [],
   "source": [
    "input_token_id = dict([(word, i + 1) for i, word in enumerate(input_words)])\n",
    "target_token_id = dict([(word, i + 1) for i, word in enumerate(target_words)])\n",
    "\n",
    "rev_input_char_id = dict((i, word) for word, i in input_token_id.items())\n",
    "rev_target_char_id = dict((i, word) for word, i in target_token_id.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9EP4jnd3YO-v",
    "outputId": "453bf47d-3923-4963-facb-a72c9d115559"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "      <th>length_en</th>\n",
       "      <th>length_ur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>1623</td>\n",
       "      <td>START_ yes for sure on the begging the scene o...</td>\n",
       "      <td>ha hai bhik magne ke scene mai andy ki party b...</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1058</td>\n",
       "      <td>START_ i do _END</td>\n",
       "      <td>ha</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>4355</td>\n",
       "      <td>START_ sure but i dont have access either _END</td>\n",
       "      <td>sure but mere pass bhi uska access nahin hai</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>2840</td>\n",
       "      <td>START_ batman intercepts a drug shipment provi...</td>\n",
       "      <td>batman ne intercepts kiya us drug shipment ko ...</td>\n",
       "      <td>249</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>3730</td>\n",
       "      <td>START_ i picked this one bc its so easy ive se...</td>\n",
       "      <td>mein is ko chuna hoon kyon ki yeh easy se dekh...</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                   english_sentence  \\\n",
       "980    1623  START_ yes for sure on the begging the scene o...   \n",
       "1609   1058                                   START_ i do _END   \n",
       "2143   4355     START_ sure but i dont have access either _END   \n",
       "1172   2840  START_ batman intercepts a drug shipment provi...   \n",
       "2347   3730  START_ i picked this one bc its so easy ive se...   \n",
       "\n",
       "                                          urdu_sentence  length_en  length_ur  \n",
       "980   ha hai bhik magne ke scene mai andy ki party b...         19         13  \n",
       "1609                                                 ha          4          1  \n",
       "2143       sure but mere pass bhi uska access nahin hai          9          9  \n",
       "1172  batman ne intercepts kiya us drug shipment ko ...        249        273  \n",
       "2347  mein is ko chuna hoon kyon ki yeh easy se dekh...         16         14  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7mYyZwxYO-w"
   },
   "source": [
    "# Splitting the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U96xDKRCYO-x",
    "outputId": "7ea5e730-66e3-4f6f-bdad-b1d75b40c1f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into 80% train and 20% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['urdu_sentence'],df['english_sentence'], test_size=0.2, random_state=42)\n",
    "\n",
    "# print(\"Train set size:\", len(x_train))\n",
    "# print(\"Test set size:\", len(x_test))\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Fg14VuvRYO-x"
   },
   "outputs": [],
   "source": [
    "def generate_batch(x = x_train, y = y_train, batch_size = 128):\n",
    "    #print(type(x_train))\n",
    "    while True:\n",
    "        for j in range(0, len(x), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_encoder_seq_length), dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_decoder_seq_length), dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(x[j:j + batch_size], y[j:j + batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_id[word]   # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):    \n",
    "                    if t < len(target_text.split()) - 1:\n",
    "                        decoder_input_data[i, t] = target_token_id[word]   # decoder input seq\n",
    "                    if t > 0:\n",
    "                        # does not include the START_ token\n",
    "                        decoder_target_data[i, t - 1, target_token_id[word]] = 1.\n",
    "            \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja4i8fHxYO-y"
   },
   "source": [
    "# Making the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jec-XDmOYO-y"
   },
   "outputs": [],
   "source": [
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qBIe7hVrYO-z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,))  # Create the input tensor\n",
    "encoder_embedding =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "# We discard encoder_outputs and only keep the states\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bUspq8-YYO-z"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using encoder_states as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    " \n",
    "# We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn encoder_input_data & decoder_input_data into decoder_target_data\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "itRNktldYO-0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dm7oYPXmYO-0",
    "outputId": "07262a19-36f4-4e9a-807a-d2346b71c9d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 256)            1897728   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 256)            1335552   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 256),                525312    ['embedding[0][0]']           \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 256),          525312    ['embedding_1[0][0]',         \n",
      "                              (None, 256),                           'lstm[0][1]',                \n",
      "                              (None, 256)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 5217)           1340769   ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5624673 (21.46 MB)\n",
      "Trainable params: 5624673 (21.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_c9OmNRDYO-0"
   },
   "outputs": [],
   "source": [
    "train_samples = len(x_train)\n",
    "val_samples = len(x_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIR25NADYO-1",
    "outputId": "88a20ee4-ccf4-462a-e6bc-335b938c4d20"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 695. MiB for an array with shape (128, 273, 5217) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgenerate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_samples\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:941\u001b[0m, in \u001b[0;36mGeneratorDataAdapter._standardize_batch.<locals>._convert_dtype\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_dtype\u001b[39m(t):\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\n\u001b[0;32m    939\u001b[0m         t\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating\n\u001b[0;32m    940\u001b[0m     ):\n\u001b[1;32m--> 941\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(t, dtype\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mfloatx())\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 695. MiB for an array with shape (128, 273, 5217) and data type float32"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    generate_batch(x_train, y_train, batch_size = batch_size),\n",
    "    steps_per_epoch = train_samples//batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = generate_batch(x_test, y_test, batch_size = batch_size),\n",
    "    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"eng_urdu_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"eng_urdu_weights.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# loading the model architecture and asigning the weights\n",
    "json_file = open('model_2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_loaded = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_loaded.load_weights(\"model_weight_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6k6u7WcYO-2"
   },
   "outputs": [],
   "source": [
    "#model.save('eng_urdu_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxflBi-GYO-2"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_inputs = model_loaded.input[0] #Trained encoder input layer\n",
    "encoder_outputs, inf_state_h, inf_state_c = model_loaded.layers[4].output # retoring the encoder lstm output and states\n",
    "encoder_states = [inf_state_h,inf_state_c]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "#inference decoder\n",
    "# The following tensor will store the state of the previous timestep in the \"starting the encoder final time step\"\n",
    "decoder_state_h_input = Input(shape=(latent_dim,)) #becase during training we have set the lstm unit to be of 50\n",
    "decoder_state_c_input = Input(shape=(latent_dim,))\n",
    "decoder_state_input = [decoder_state_h_input,decoder_state_c_input]\n",
    "\n",
    "# # inference decoder input\n",
    "decoder_input_inf = model_loaded.input[1] #Trained decoder input layer\n",
    "# decoder_input_inf._name='decoder_input'\n",
    "decoder_emb_inf = model_loaded.layers[3](decoder_input_inf)\n",
    "decoder_lstm_inf = model_loaded.layers[5]\n",
    "decoder_output_inf, decoder_state_h_inf, decoder_state_c_inf = decoder_lstm_inf(decoder_emb_inf, initial_state =decoder_state_input)\n",
    "decoder_state_inf = [decoder_state_h_inf,decoder_state_c_inf]\n",
    "#inference dense layer\n",
    "dense_inf = model_loaded.layers[6]\n",
    "decoder_output_final = dense_inf(decoder_output_inf)# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "decoder_model = Model([decoder_input_inf]+decoder_state_input,[decoder_output_final]+decoder_state_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRcgVljDYO-2"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_id['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    decoded_sentence = ''\n",
    "    while True:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = rev_target_char_id[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or len(decoded_sentence) > 50):\n",
    "            break\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUotQRW-YO-3"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(x_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mzjd-DM9YO-3",
    "outputId": "d257f735-8a8b-4d5c-819c-4a1362db3da8"
   },
   "outputs": [],
   "source": [
    "urdu_sentence= input('Enter urdu sentence: ')\n",
    "tokenizer_input= Tokenizer()\n",
    "input_seq= tokenizer_input.texts_to_sequences([urdu_sentence])\n",
    "pad_seq= pad_sequences(input_seq)\n",
    "predicted_target = decode_sequence(pad_seq)\n",
    "print(\"predicted Translate:\",predicted_target[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3VpE5tiYO-4",
    "outputId": "79cccfd0-3f2a-4410-bbc8-293b80e11766"
   },
   "outputs": [],
   "source": [
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQuGtMCHYO-4",
    "outputId": "23455309-2ebd-4da7-e846-f5f6430768a6"
   },
   "outputs": [],
   "source": [
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNriQxDwYO-5",
    "outputId": "71224763-3e36-4e70-eb79-e29d332b5a22"
   },
   "outputs": [],
   "source": [
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLLpQxpRYO-6",
    "outputId": "56be6286-079f-4ef2-e9f2-cd6ea79c1200"
   },
   "outputs": [],
   "source": [
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the weights into your model\n",
    "#model.load_weights('eng_urdu_weights.h5')\n",
    "\n",
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate probability over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_id['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    decoded_sentence = ''\n",
    "    while True:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = rev_target_char_id[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or len(decoded_sentence) > 50):\n",
    "            break\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "train_gen = generate_batch(x_train, y_train, batch_size=1)\n",
    "k=-1\n",
    "\n",
    "k += 1\n",
    "# (input_seq, actual_output), _ = next(train_gen)\n",
    "# print(type(input_seq))\n",
    "# decoded_sentence = decode_sequence(input_seq)\n",
    "# print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "# print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "# print('Predicted urdu Translation:', decoded_sentence[:-4])\n",
    "\n",
    "# urdu_sentence= input('Enter urdu sentence: ')\n",
    "# tokenizer_input= Tokenizer()\n",
    "# input_seq= tokenizer_input.texts_to_sequences([urdu_sentence])\n",
    "# pad_seq= pad_sequences(input_seq)\n",
    "# predicted_target = decode_sequence(pad_seq)\n",
    "# print(\"predicted Translate:\",predicted_target[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "meme",
   "language": "python",
   "name": "meme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8bba4f2be892cbd4f39a9f240acc2c7ebb8cef7264d56c87dbb8c6b0bcbe231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
