{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pradeep2c1/Machine-Translation-model/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aByTLISdCSpp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    " \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvs3YYFrYXmN",
    "outputId": "936355b6-4805-4255-f2db-63446474b132"
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "kcz51fdAYp_8",
    "outputId": "08d6dc6e-ce6b-4b7f-8283-70d0864babe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4dOWFN2YO83"
   },
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8B5h0UHMmEgQ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'urdu_english.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REzTYEAEmYlu",
    "outputId": "656c2d6d-8995-4fdc-f500-5960b824bd05"
   },
   "outputs": [],
   "source": [
    "#df['source'].value_counts()\n",
    "df= df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "NU6z_ZbLs8N7",
    "outputId": "dd856585-db0d-4035-ece1-25fe770eafce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what's the name of the movie</td>\n",
       "      <td>film ka kya naam hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi, the rotten tomatoes score is great but the...</td>\n",
       "      <td>namaste, sada hua tomatoes score mahaan hai, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do you think you will like the movie</td>\n",
       "      <td>kya aapako lagata hai ki aapako film pasand aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what kind of movie is it</td>\n",
       "      <td>yah kis tarah kee philm hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when was the movie made?</td>\n",
       "      <td>film  kab banee thee?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wonder woman, i think i would enjoy this movie...</td>\n",
       "      <td>aashchary hai ki mahila, mujhe lagata hai ki m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>whats the name of the movie</td>\n",
       "      <td>film ka kya naam hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it is a action movie set in the dc comic world</td>\n",
       "      <td>yah deesee komik duniya mein sthaapit ek eksha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>who stars in the movie</td>\n",
       "      <td>: film mein kaun sitaare hain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the movie was made in 2015</td>\n",
       "      <td>movie 2015 mein banee thee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    english_sentence  \\\n",
       "0                       what's the name of the movie   \n",
       "1  hi, the rotten tomatoes score is great but the...   \n",
       "2               do you think you will like the movie   \n",
       "3                           what kind of movie is it   \n",
       "4                           when was the movie made?   \n",
       "5  wonder woman, i think i would enjoy this movie...   \n",
       "6                        whats the name of the movie   \n",
       "7     it is a action movie set in the dc comic world   \n",
       "8                             who stars in the movie   \n",
       "9                         the movie was made in 2015   \n",
       "\n",
       "                                       urdu_sentence  \n",
       "0                               film ka kya naam hai  \n",
       "1  namaste, sada hua tomatoes score mahaan hai, l...  \n",
       "2  kya aapako lagata hai ki aapako film pasand aa...  \n",
       "3                        yah kis tarah kee philm hai  \n",
       "4                              film  kab banee thee?  \n",
       "5  aashchary hai ki mahila, mujhe lagata hai ki m...  \n",
       "6                               film ka kya naam hai  \n",
       "7  yah deesee komik duniya mein sthaapit ek eksha...  \n",
       "8                      : film mein kaun sitaare hain  \n",
       "9                         movie 2015 mein banee thee  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df[df['source'] == 'ted']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWUF8i3eNBNG",
    "outputId": "f3baa0b6-982b-42f1-f235-5b3704c179b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.drop(columns = ['source'], inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8Y7POK6xYn3r"
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)\n",
    "#df.drop(columns = ['index'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmpewEf60IGd",
    "outputId": "2256d44f-a7fa-46e2-a4e5-eb0f422d47ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index               0\n",
       "english_sentence    0\n",
       "urdu_sentence       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbHkhHLk8_S0",
    "outputId": "f79a482f-a6fc-4ee0-f998-52298d1b2f55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jLLZJ7tdX_38",
    "outputId": "951f88a8-5fc6-4cd7-a85f-7a86ee87a007"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what's the name of the movie</td>\n",
       "      <td>film ka kya naam hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hi, the rotten tomatoes score is great but the...</td>\n",
       "      <td>namaste, sada hua tomatoes score mahaan hai, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>do you think you will like the movie</td>\n",
       "      <td>kya aapako lagata hai ki aapako film pasand aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what kind of movie is it</td>\n",
       "      <td>yah kis tarah kee philm hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>when was the movie made?</td>\n",
       "      <td>film  kab banee thee?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   english_sentence  \\\n",
       "0      0                       what's the name of the movie   \n",
       "1      1  hi, the rotten tomatoes score is great but the...   \n",
       "2      2               do you think you will like the movie   \n",
       "3      3                           what kind of movie is it   \n",
       "4      4                           when was the movie made?   \n",
       "\n",
       "                                       urdu_sentence  \n",
       "0                               film ka kya naam hai  \n",
       "1  namaste, sada hua tomatoes score mahaan hai, l...  \n",
       "2  kya aapako lagata hai ki aapako film pasand aa...  \n",
       "3                        yah kis tarah kee philm hai  \n",
       "4                              film  kab banee thee?  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vtTASV7GHewD"
   },
   "outputs": [],
   "source": [
    "# Make all english letters lowercase\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove the quotes\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df['urdu_sentence'] = df['urdu_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "# Remove special characters\n",
    "sp_char = set(string.punctuation)\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in sp_char))\n",
    "df['urdu_sentence'] = df['urdu_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in sp_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KfuxP2pXYO9E"
   },
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: x.strip())\n",
    "df['urdu_sentence']=df['urdu_sentence'].apply(lambda x: x.strip())\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "df['urdu_sentence']=df['urdu_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RJZsWTHZnlY1"
   },
   "outputs": [],
   "source": [
    "# Add START and END tokens to the beginning and end of the target sequence\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: 'START_ ' + x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "O1jcj84GLMVM",
    "outputId": "f6d2fbf8-24a8-42b1-93fc-ef443246bde8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>START_ whats the name of the movie _END</td>\n",
       "      <td>film ka kya naam hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>START_ hi the rotten tomatoes score is great b...</td>\n",
       "      <td>namaste sada hua tomatoes score mahaan hai lek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>START_ do you think you will like the movie _END</td>\n",
       "      <td>kya aapako lagata hai ki aapako film pasand aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>START_ what kind of movie is it _END</td>\n",
       "      <td>yah kis tarah kee philm hai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>START_ when was the movie made _END</td>\n",
       "      <td>film kab banee thee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   english_sentence  \\\n",
       "0      0            START_ whats the name of the movie _END   \n",
       "1      1  START_ hi the rotten tomatoes score is great b...   \n",
       "2      2   START_ do you think you will like the movie _END   \n",
       "3      3               START_ what kind of movie is it _END   \n",
       "4      4                START_ when was the movie made _END   \n",
       "\n",
       "                                       urdu_sentence  \n",
       "0                               film ka kya naam hai  \n",
       "1  namaste sada hua tomatoes score mahaan hai lek...  \n",
       "2  kya aapako lagata hai ki aapako film pasand aa...  \n",
       "3                        yah kis tarah kee philm hai  \n",
       "4                                film kab banee thee  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6tOma5CQYl8X",
    "outputId": "db46aef2-51d0-4293-98ab-c36115d64a23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3408</td>\n",
       "      <td>START_ i am not sure how long the movie is if ...</td>\n",
       "      <td>mujhe yakeen nahin hai ki philm kitanee lambee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4440</td>\n",
       "      <td>START_ huge bugdet did it make it back lol _END</td>\n",
       "      <td>huge budget na kya unko fir se mila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>START_ yes ive watched the wolf of wall street...</td>\n",
       "      <td>haan mein the wolf of wall street ko dekha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>715</td>\n",
       "      <td>START_ yes it stars benedict cumberbatch and k...</td>\n",
       "      <td>ha iss me benedict cumberbatch and keira knigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703</td>\n",
       "      <td>START_ another said is too calculated to refle...</td>\n",
       "      <td>dusra kaha kiaajkal ka ragged tho thoda reflec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   english_sentence  \\\n",
       "0   3408  START_ i am not sure how long the movie is if ...   \n",
       "1   4440    START_ huge bugdet did it make it back lol _END   \n",
       "2     98  START_ yes ive watched the wolf of wall street...   \n",
       "3    715  START_ yes it stars benedict cumberbatch and k...   \n",
       "4   1703  START_ another said is too calculated to refle...   \n",
       "\n",
       "                                       urdu_sentence  \n",
       "0  mujhe yakeen nahin hai ki philm kitanee lambee...  \n",
       "1                huge budget na kya unko fir se mila  \n",
       "2         haan mein the wolf of wall street ko dekha  \n",
       "3  ha iss me benedict cumberbatch and keira knigh...  \n",
       "4  dusra kaha kiaajkal ka ragged tho thoda reflec...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1).reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQY65UsEYO-h"
   },
   "source": [
    "# Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "z6Gh2jx0YO-j"
   },
   "outputs": [],
   "source": [
    "en = set()\n",
    "for sentence in df['english_sentence']:\n",
    "    for word in sentence.split():\n",
    "        if word not in en:\n",
    "            en.add(word)\n",
    "\n",
    "hi = set()\n",
    "for sentence in df['urdu_sentence']:\n",
    "    for word in sentence.split():\n",
    "        if word not in hi:\n",
    "            hi.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KV8sLvrnYO-k",
    "outputId": "87a1833c-aeab-44b4-811a-50cc1143b035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in English are :  5216\n",
      "Unique words in urdu are :  7411\n"
     ]
    }
   ],
   "source": [
    "print('Unique words in English are : ', len(en))\n",
    "print('Unique words in urdu are : ', len(hi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NBF2-ex1YO-m",
    "outputId": "12e90d91-f677-43be-fa97-f10d93a859ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "      <th>length_en</th>\n",
       "      <th>length_ur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3408</td>\n",
       "      <td>START_ i am not sure how long the movie is if ...</td>\n",
       "      <td>mujhe yakeen nahin hai ki philm kitanee lambee...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4440</td>\n",
       "      <td>START_ huge bugdet did it make it back lol _END</td>\n",
       "      <td>huge budget na kya unko fir se mila</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>START_ yes ive watched the wolf of wall street...</td>\n",
       "      <td>haan mein the wolf of wall street ko dekha</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>715</td>\n",
       "      <td>START_ yes it stars benedict cumberbatch and k...</td>\n",
       "      <td>ha iss me benedict cumberbatch and keira knigh...</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703</td>\n",
       "      <td>START_ another said is too calculated to refle...</td>\n",
       "      <td>dusra kaha kiaajkal ka ragged tho thoda reflec...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   english_sentence  \\\n",
       "0   3408  START_ i am not sure how long the movie is if ...   \n",
       "1   4440    START_ huge bugdet did it make it back lol _END   \n",
       "2     98  START_ yes ive watched the wolf of wall street...   \n",
       "3    715  START_ yes it stars benedict cumberbatch and k...   \n",
       "4   1703  START_ another said is too calculated to refle...   \n",
       "\n",
       "                                       urdu_sentence  length_en  length_ur  \n",
       "0  mujhe yakeen nahin hai ki philm kitanee lambee...         20         19  \n",
       "1                huge budget na kya unko fir se mila         10          8  \n",
       "2         haan mein the wolf of wall street ko dekha         10          9  \n",
       "3  ha iss me benedict cumberbatch and keira knigh...         21         19  \n",
       "4  dusra kaha kiaajkal ka ragged tho thoda reflec...         14         15  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length_en'] = df['english_sentence'].apply(lambda x: len(x.split()))\n",
    "df['length_ur'] = df['urdu_sentence'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBdYEMDCYO-o",
    "outputId": "70c3250d-83f5-47d3-980a-9a39ee01443e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(747, 5)\n",
      "(657, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df[df['length_en'] > 20].shape)\n",
    "print(df[df['length_ur'] > 20].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EleKwN6ZYO-p",
    "outputId": "ecc9b403-03b1-472a-df96-08f33c3609dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4182, 5)\n"
     ]
    }
   ],
   "source": [
    "df = df[df['length_en'] <= 20]\n",
    "df = df[df['length_ur'] <= 20]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTgOsAssYO-q",
    "outputId": "51c3acdb-1f9d-4f15-8b05-a91b82c353a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length of inputs = 20\n",
      "Maximum sequence length of outputs = 20\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum sequence length of inputs =\", max(df['length_en']))\n",
    "print(\"Maximum sequence length of outputs =\", max(df['length_ur']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6U7JUwqYO-r",
    "outputId": "1c0a906a-8f52-402a-ca5f-b3221cae7f8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7411, 5216)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_encoder_seq_length = max(df['length_en'])\n",
    "max_decoder_seq_length = max(df['length_ur'])\n",
    "\n",
    "input_words = sorted(list(hi))\n",
    "target_words = sorted(list(en))\n",
    "num_encoder_tokens = len(hi)\n",
    "num_decoder_tokens = len(en)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5iP6_8xWYO-s"
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens += 1\n",
    "num_decoder_tokens += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HwHCkRaCYO-s"
   },
   "outputs": [],
   "source": [
    "input_token_id = dict([(word, i + 1) for i, word in enumerate(input_words)])\n",
    "target_token_id = dict([(word, i + 1) for i, word in enumerate(target_words)])\n",
    "\n",
    "rev_input_char_id = dict((i, word) for word, i in input_token_id.items())\n",
    "rev_target_char_id = dict((i, word) for word, i in target_token_id.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9EP4jnd3YO-v",
    "outputId": "453bf47d-3923-4963-facb-a72c9d115559"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>urdu_sentence</th>\n",
       "      <th>length_en</th>\n",
       "      <th>length_ur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>1111</td>\n",
       "      <td>START_ it is a favorite among my children _END</td>\n",
       "      <td>ye mere baccho kaa favorite hai</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>2176</td>\n",
       "      <td>START_ not much of a talker huh _END</td>\n",
       "      <td>jyaada baat karane vaala huh nahin</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>464</td>\n",
       "      <td>START_ oh nice _END</td>\n",
       "      <td>acha nice hein</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>58</td>\n",
       "      <td>START_ do you like jim carey in comedy _END</td>\n",
       "      <td>kya tum ko jim carey comedy mei pasand hai</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>1339</td>\n",
       "      <td>START_ no he is right _END</td>\n",
       "      <td>nahin vah sahee hai</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                english_sentence  \\\n",
       "917    1111  START_ it is a favorite among my children _END   \n",
       "1125   2176            START_ not much of a talker huh _END   \n",
       "2179    464                             START_ oh nice _END   \n",
       "4239     58     START_ do you like jim carey in comedy _END   \n",
       "4858   1339                      START_ no he is right _END   \n",
       "\n",
       "                                   urdu_sentence  length_en  length_ur  \n",
       "917              ye mere baccho kaa favorite hai          9          6  \n",
       "1125          jyaada baat karane vaala huh nahin          8          6  \n",
       "2179                              acha nice hein          4          3  \n",
       "4239  kya tum ko jim carey comedy mei pasand hai          9          9  \n",
       "4858                         nahin vah sahee hai          6          4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7mYyZwxYO-w"
   },
   "source": [
    "# Splitting the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U96xDKRCYO-x",
    "outputId": "7ea5e730-66e3-4f6f-bdad-b1d75b40c1f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 3345\n",
      "Test set size: 837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into 80% train and 20% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['urdu_sentence'],df['english_sentence'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train set size:\", len(x_train))\n",
    "print(\"Test set size:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Fg14VuvRYO-x"
   },
   "outputs": [],
   "source": [
    "def generate_batch(x = x_train, y = y_train, batch_size = 128):\n",
    "    while True:\n",
    "        for j in range(0, len(x), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_encoder_seq_length), dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_decoder_seq_length), dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(x[j:j + batch_size], y[j:j + batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_id[word]   # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):    \n",
    "                    if t < len(target_text.split()) - 1:\n",
    "                        decoder_input_data[i, t] = target_token_id[word]   # decoder input seq\n",
    "                    if t > 0:\n",
    "                        # does not include the START_ token\n",
    "                        decoder_target_data[i, t - 1, target_token_id[word]] = 1. \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja4i8fHxYO-y"
   },
   "source": [
    "# Making the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jec-XDmOYO-y"
   },
   "outputs": [],
   "source": [
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qBIe7hVrYO-z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,))  # Create the input tensor\n",
    "encoder_embedding =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "# We discard encoder_outputs and only keep the states\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bUspq8-YYO-z"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using encoder_states as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    " \n",
    "# We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn encoder_input_data & decoder_input_data into decoder_target_data\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "itRNktldYO-0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dm7oYPXmYO-0",
    "outputId": "07262a19-36f4-4e9a-807a-d2346b71c9d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 256)            1897472   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 256)            1335552   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 256),                525312    ['embedding[0][0]']           \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 256),          525312    ['embedding_1[0][0]',         \n",
      "                              (None, 256),                           'lstm[0][1]',                \n",
      "                              (None, 256)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 5217)           1340769   ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5624417 (21.46 MB)\n",
      "Trainable params: 5624417 (21.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_c9OmNRDYO-0"
   },
   "outputs": [],
   "source": [
    "train_samples = len(x_train)\n",
    "val_samples = len(x_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIR25NADYO-1",
    "outputId": "88a20ee4-ccf4-462a-e6bc-335b938c4d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "26/26 [==============================] - 46s 1s/step - loss: 7.3967 - val_loss: 6.0854\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 22s 851ms/step - loss: 5.8529 - val_loss: 5.8081\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 23s 885ms/step - loss: 5.6505 - val_loss: 5.7309\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 23s 874ms/step - loss: 5.5383 - val_loss: 5.6382\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 22s 838ms/step - loss: 5.4377 - val_loss: 5.5503\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 21s 820ms/step - loss: 5.3357 - val_loss: 5.5362\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 23s 892ms/step - loss: 5.2482 - val_loss: 5.5365\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 21s 823ms/step - loss: 5.1763 - val_loss: 5.5284\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 22s 851ms/step - loss: 5.1011 - val_loss: 5.4344\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 21s 813ms/step - loss: 5.0325 - val_loss: 5.4273\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 21s 804ms/step - loss: 4.9553 - val_loss: 5.3623\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 24s 925ms/step - loss: 4.8717 - val_loss: 5.2976\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 23s 888ms/step - loss: 4.7802 - val_loss: 5.2724\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 21s 795ms/step - loss: 4.6981 - val_loss: 5.2413\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 21s 820ms/step - loss: 4.6164 - val_loss: 5.2368\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 21s 793ms/step - loss: 4.5355 - val_loss: 5.1224\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 21s 810ms/step - loss: 4.4627 - val_loss: 5.1411\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 20s 791ms/step - loss: 4.3991 - val_loss: 5.0842\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 24s 917ms/step - loss: 4.3429 - val_loss: 5.0760\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 21s 831ms/step - loss: 4.2587 - val_loss: 5.0902\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 22s 870ms/step - loss: 4.1980 - val_loss: 5.1075\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 21s 820ms/step - loss: 4.1328 - val_loss: 5.1446\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 24s 933ms/step - loss: 4.0930 - val_loss: 5.0707\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 22s 840ms/step - loss: 4.0437 - val_loss: 5.0466\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 21s 810ms/step - loss: 4.0073 - val_loss: 5.0210\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 23s 886ms/step - loss: 3.9380 - val_loss: 5.0153\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 22s 848ms/step - loss: 3.8513 - val_loss: 5.0089\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 25s 953ms/step - loss: 3.8235 - val_loss: 5.0351\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 24s 925ms/step - loss: 3.7276 - val_loss: 5.0836\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 22s 838ms/step - loss: 3.6719 - val_loss: 4.9837\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 20s 774ms/step - loss: 3.6319 - val_loss: 4.9922\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 20s 790ms/step - loss: 3.5870 - val_loss: 4.9788\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 20s 788ms/step - loss: 3.5189 - val_loss: 4.9733\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 20s 775ms/step - loss: 3.4469 - val_loss: 4.9797\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 22s 838ms/step - loss: 3.3913 - val_loss: 5.0204\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 24s 923ms/step - loss: 3.3325 - val_loss: 5.0444\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 3.2823 - val_loss: 4.9431\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 24s 921ms/step - loss: 3.2323 - val_loss: 4.9893\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 25s 967ms/step - loss: 3.1888 - val_loss: 4.9486\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 21s 804ms/step - loss: 3.1337 - val_loss: 4.9824\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 23s 872ms/step - loss: 3.0751 - val_loss: 5.0014\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 21s 818ms/step - loss: 3.0201 - val_loss: 5.0143\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 23s 870ms/step - loss: 2.9601 - val_loss: 5.0643\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 22s 835ms/step - loss: 2.8973 - val_loss: 5.0061\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 23s 877ms/step - loss: 2.8445 - val_loss: 4.9995\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 20s 781ms/step - loss: 2.7980 - val_loss: 4.9951\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 22s 847ms/step - loss: 2.7445 - val_loss: 5.0908\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 22s 864ms/step - loss: 2.6969 - val_loss: 5.0470\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 22s 842ms/step - loss: 2.6482 - val_loss: 5.0954\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 22s 838ms/step - loss: 2.6056 - val_loss: 5.1354\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 23s 877ms/step - loss: 2.5546 - val_loss: 5.0083\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 22s 840ms/step - loss: 2.5071 - val_loss: 5.0480\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 22s 823ms/step - loss: 2.4589 - val_loss: 5.0259\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 22s 835ms/step - loss: 2.4023 - val_loss: 5.0765\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 21s 814ms/step - loss: 2.4168 - val_loss: 5.0757\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 21s 818ms/step - loss: 2.3068 - val_loss: 5.1435\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 21s 798ms/step - loss: 2.2516 - val_loss: 5.2046\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 20s 782ms/step - loss: 2.2154 - val_loss: 5.0898\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 21s 801ms/step - loss: 2.1656 - val_loss: 5.1400\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 21s 792ms/step - loss: 2.1247 - val_loss: 5.1241\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 21s 827ms/step - loss: 2.0802 - val_loss: 5.2020\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 21s 824ms/step - loss: 2.0307 - val_loss: 5.2820\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 22s 840ms/step - loss: 1.9911 - val_loss: 5.2962\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 21s 826ms/step - loss: 1.9554 - val_loss: 5.3584\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 21s 810ms/step - loss: 1.9093 - val_loss: 5.1897\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 21s 796ms/step - loss: 1.8697 - val_loss: 5.2066\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 20s 788ms/step - loss: 1.8272 - val_loss: 5.2058\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 22s 836ms/step - loss: 1.7815 - val_loss: 5.2673\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 21s 797ms/step - loss: 1.7598 - val_loss: 5.2681\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 21s 794ms/step - loss: 1.7145 - val_loss: 5.2846\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 21s 793ms/step - loss: 1.6626 - val_loss: 5.3518\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 1.6201 - val_loss: 5.3015\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 21s 796ms/step - loss: 1.5766 - val_loss: 5.3505\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 21s 803ms/step - loss: 1.5348 - val_loss: 5.3143\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 20s 789ms/step - loss: 1.4942 - val_loss: 5.3443\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 21s 808ms/step - loss: 1.4465 - val_loss: 5.3645\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 1.4094 - val_loss: 5.4039\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 21s 797ms/step - loss: 1.3771 - val_loss: 5.4472\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 21s 808ms/step - loss: 1.3383 - val_loss: 5.3706\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 21s 792ms/step - loss: 1.3039 - val_loss: 5.4233\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 21s 798ms/step - loss: 1.2675 - val_loss: 5.4652\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 23s 872ms/step - loss: 1.2709 - val_loss: 5.5468\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 21s 811ms/step - loss: 1.1953 - val_loss: 5.5380\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 21s 826ms/step - loss: 1.1622 - val_loss: 5.5939\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 22s 841ms/step - loss: 1.1320 - val_loss: 5.6309\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 20s 786ms/step - loss: 1.0974 - val_loss: 5.5253\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 1.0655 - val_loss: 5.5770\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 21s 791ms/step - loss: 1.0298 - val_loss: 5.5660\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 20s 780ms/step - loss: 0.9996 - val_loss: 5.6196\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 21s 829ms/step - loss: 0.9662 - val_loss: 5.6326\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 23s 903ms/step - loss: 0.9437 - val_loss: 5.6864\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 23s 864ms/step - loss: 0.9176 - val_loss: 5.7567\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 24s 910ms/step - loss: 0.8914 - val_loss: 5.6766\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 24s 912ms/step - loss: 0.8656 - val_loss: 5.7039\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 23s 903ms/step - loss: 0.8424 - val_loss: 5.6977\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 23s 885ms/step - loss: 0.8207 - val_loss: 5.7669\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 23s 904ms/step - loss: 0.7990 - val_loss: 5.7701\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 22s 847ms/step - loss: 0.7692 - val_loss: 5.8507\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 23s 880ms/step - loss: 0.7442 - val_loss: 5.8992\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 23s 873ms/step - loss: 0.7204 - val_loss: 5.8365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29bdd5f8a10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    generate_batch(x_train, y_train, batch_size = batch_size),\n",
    "    steps_per_epoch = train_samples//batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = generate_batch(x_test, y_test, batch_size = batch_size),\n",
    "    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "W6k6u7WcYO-2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AAHIL ALWANI\\Desktop\\FYP\\Web App\\Meme_AI\\meme\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('eng_urdu_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "kxflBi-GYO-2"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape = (latent_dim,))\n",
    "decoder_state_input_c = Input(shape = (latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate probability over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "BRcgVljDYO-2"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_id['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    decoded_sentence = ''\n",
    "    while True:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = rev_target_char_id[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or len(decoded_sentence) > 50):\n",
    "            break\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "pUotQRW-YO-3"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(x_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mzjd-DM9YO-3",
    "outputId": "d257f735-8a8b-4d5c-819c-4a1362db3da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Input urdu sentence: movie ka name kya hai\n",
      "Actual english Translation:  what is the name of the movie \n",
      "Predicted english Translation:  whats the name of the movie \n"
     ]
    }
   ],
   "source": [
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input urdu sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual english Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted english Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3VpE5tiYO-4",
    "outputId": "79cccfd0-3f2a-4410-bbc8-293b80e11766"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Input English sentence: kya aapko nahi lagtha characters sab dull hei\n",
      "Actual urdu Translation:  did you think the characters were dull \n",
      "Predicted urdu Translation:  did you think the characters were dull \n"
     ]
    }
   ],
   "source": [
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQuGtMCHYO-4",
    "outputId": "23455309-2ebd-4da7-e846-f5f6430768a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Input English sentence: sometimes\n",
      "Actual urdu Translation:  sometimes \n",
      "Predicted urdu Translation:  sometimes \n"
     ]
    }
   ],
   "source": [
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNriQxDwYO-5",
    "outputId": "71224763-3e36-4e70-eb79-e29d332b5a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Input English sentence: fir usne socha ki gru ko vector par try karna chahiye us moon ko off karne pe\n",
      "Actual urdu Translation:  he then thought gru should try to help vector off the moon \n",
      "Predicted urdu Translation:  he plays lucious fox i think he was a very enjoy\n"
     ]
    }
   ],
   "source": [
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLLpQxpRYO-6",
    "outputId": "56be6286-079f-4ef2-e9f2-cd6ea79c1200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Input English sentence: frank kamal ka character tha\n",
      "Actual urdu Translation:  frank is quite a character \n",
      "Predicted urdu Translation:  frank is quite a character \n"
     ]
    }
   ],
   "source": [
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Input English sentence: movie ka name kya hai\n",
      "Actual urdu Translation:  what is the name of the movie \n",
      "Predicted urdu Translation:  whats the name of the movie \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the weights into your model\n",
    "model.load_weights('eng_urdu_weights.h5')\n",
    "\n",
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate probability over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_id['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    decoded_sentence = ''\n",
    "    while True:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = rev_target_char_id[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or len(decoded_sentence) > 50):\n",
    "            break\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "train_gen = generate_batch(x_train, y_train, batch_size=1)\n",
    "k=-1\n",
    "\n",
    "k += 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
    "print('Actual urdu Translation:', y_train[k:k + 1].values[0][6:-4])\n",
    "print('Predicted urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "meme",
   "language": "python",
   "name": "meme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8bba4f2be892cbd4f39a9f240acc2c7ebb8cef7264d56c87dbb8c6b0bcbe231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
