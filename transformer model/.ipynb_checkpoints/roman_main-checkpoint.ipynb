{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3739f21-a9cd-4bf0-bc1f-6ccdb2744c74",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eng_to_urdu_new'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, LSTM, Embedding, Dense\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meng_to_urdu_new\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipynb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m x_train, y_train\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'eng_to_urdu_new'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model,load_model\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b3f826c-168c-435f-8816-5f6904cc6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = set()\n",
    "for sentence in df['english_sentence']:\n",
    "    for word in sentence.split():\n",
    "        if word not in en:\n",
    "            en.add(word)\n",
    "\n",
    "hi = set()\n",
    "for sentence in df['urdu_sentence']:\n",
    "    for word in sentence.split():\n",
    "        if word not in hi:\n",
    "            hi.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15b901cd-51a1-4c8d-af52-7fd6a4570b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46839, 40566)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'urdu_english.csv', encoding='utf-8')\n",
    "df['length_en'] = df['english_sentence'].apply(lambda x: len(x.split()))\n",
    "df['length_ur'] = df['urdu_sentence'].apply(lambda x: len(x.split()))\n",
    "max_encoder_seq_length = max(df['length_en'])\n",
    "max_decoder_seq_length = max(df['length_ur'])\n",
    "\n",
    "num_encoder_tokens = len(hi)\n",
    "num_decoder_tokens = len(en)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10dae006-6e76-4357-baea-c11b167a8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens += 1\n",
    "num_decoder_tokens += 1\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c58057ed-5051-4a9b-9563-74beab865366",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))  # Create the input tensor\n",
    "encoder_embedding =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "# We discard encoder_outputs and only keep the states\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9392fbd3-882d-485b-9738-42278ecf2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using encoder_states as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    " \n",
    "# We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac84cc61-dbfe-4a89-a1e5-5a93528f36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model =load_model('eng_urdu_weights.h5')\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape = (latent_dim,))\n",
    "decoder_state_input_c = Input(shape = (latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate probability over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b974c93e-a726-4a3c-a4e4-b220c2f65959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_id['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    decoded_sentence = ''\n",
    "    while True:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = rev_target_char_id[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or len(decoded_sentence) > 50):\n",
    "            break\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e5c14-2071-40c1-930c-a9e83c4a96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator\n",
    "train_gen = generate_batch(x_train, y_train, batch_size=1)\n",
    "\n",
    "# Get user input for Roman Urdu sentence\n",
    "user_input = input(\"Enter a Roman Urdu sentence: \")\n",
    "\n",
    "# Preprocess the user input (assuming you have a preprocessing function)\n",
    "processed_input = preprocess_input(user_input)\n",
    "\n",
    "# Convert the input sentence to the input sequence format expected by your model\n",
    "input_seq = convert_to_input_sequence(processed_input)\n",
    "\n",
    "# Generate the English translation\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "# Print the input Roman Urdu sentence, actual English translation, and predicted English translation\n",
    "print('Input Urdu sentence:', user_input)\n",
    "print('Predicted English Translation:', decoded_sentence[:-4])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meme",
   "language": "python",
   "name": "meme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
